behaviors:
    Agent:
        trainer_type: ppo
        hyperparameters:
            batch_size: 2000
            buffer_size: 20000
        network_settings:
            hidden_units: 500
            num_layers: 3
        reward_signals:
            extrinsic:
                gamma: 0.99
        self_play:
            window: 20
            play_against_latest_model_ratio: 0.3
        time_horizon: 300
        max_steps: 1e6
        threaded: true
        summary_freq: 20000
engine_settings:
  width: 640
  height: 360